Что такое Hadoop?
Набор инструментов, библиотек который предназначен для построения надежного хранилища и организации распределённых вычислений.
Фреймворк который помогает обеспечить достаточно надежное хранение и быструю обработку данных.
Фреймворк, предназначенный для построения распределённых приложений для работы с данными очень большого объёма.
Реализует вычислительную парадигму MapReduce, в которой приложение разбивается на множество независимых частей, каждая из которых может исполняться на отдельном узле.
Что такое HDFS?
Распределенная файловая система Hadoop для хранения файлов больших размеров, поблочно распределенных между узлами вычислительного кластера. Все блоки в HDFS 6кроме последнего блока файла) имеют одинаковый размер, и каждый блок может быть размещен на нескольких узлах, размер блока и коэффициент репликации 6количество узлов, на которых должен быть размещён каждый блок) определяются в настройках на уровне файла. Благодаря репликации обеспечивается устойчивость распределенной системы к отказам отдельных узлов. Файлы в HDFS могут быть записаны лишь однажды 6модификация не поддерживается), а запись в файл в одно время может вести только один процесс.
Это основное распределенное хранилище, используемое приложениями Hadoop. Кластер HDFS в основном состоит из NameNode, который управляет метаданными файловой системы, и DataNode, в которых хранятся фактические данные.
*Что такое YARN?
это система для планирования заданий и управления кластером.
Будучи одним из основных компонентов Apache Hadoop, YARN отвечает за распределение системных ресурсов различным приложениям, работающим в кластере Hadoop, и за и планирование задач, выполняемых на разных узлах кластера.
Ещё один ресурсный менеджер. Позволяет управлять нагрузкой на кластер, на конкретное НОДЕ, ресурсами этого кластера, и в зависимости от кол-ва задач перераспределять , т.е. управлять утилизацией наших ресурсов. 2.Отслеживать состояние задач т.е. Выполнились не выполнились, перезапустить при необходимости.
модуль, отвечающий за управление ресурсами кластеров и планирование заданий. YARN функционирует как самостоятельный демон — планировщик ресурсов, абстрагирующий все вычислительные ресурсы кластера и управляющий их предоставлением приложениям распределённой обработки. Под управлением YARN могут работать как MapReduce- программы, так и любые другие распределённые приложения, поддерживающие соответствующие программные интерфейсы. YARN обеспечивает возможность параллельного выполнения нескольких различных задач в рамках кластера и их изоляцию по принципам мультиарендности.
Какие минусы или опасные места HDFS?- Основная задача HDFS - надежное хранение данных даже в случае сбоев. Наиболее распространены три типа сбоев: сбои NameNode, сбои DataNode и сетевые разделы.
Отказ диска данных, heartbeat и повторная репликация, Перебалансировка кластеров, Целостность данных, Ошибка метаданных на диске.
Файлы в HDFS могут быть записаны лишь однажды 6модификация не поддерживается), а запись в файл в одно время может вести только один процесс.
Слабые места заключается в том, что все промежуточные результаты сохраняются на диск и передаются через сеть, что замедляется процесс по сравнению с операциями в памяти.
Что такое блок HDFS?
это единица хранения данных . Управляется через Namenode - Хранится на Datanode. Реплицируются по машинам в процессе записи - Оддин и тот же блок хранится на нескольких Datanode - фактор репликации по умолчанию равен 3 - это нужен для fault-tolerance и упрощения доступа. Размер блоков 128мб - Основной мотив этого - снизить стоимость seek time по сравнению со скоростью передачи данных 6transfer rate)
Для чего используется NameNode?
NameNode – это отдельный, единственный в кластере, сервер с программным кодом для управления пространством имен файловой системы, хранящий дерево файлов, а также мета-данные файлов и каталогов.
Узел имен 6NameNode) – программный код, выполняющийся, в общем случае, на выделенной машине экземпляра HDFS и отвечающий за файловые операции 6работу с метаданными);
NameNode отвечает за управление метаданными всей файловой системы, в которой хранятся записи данных и путь к хранилищу данных
Для чего используется DataNode?
DataNode – обязательный компонент кластера HDFS, который отвечает за запись и чтение данных, выполнение команд от узла NameNode по созданию, удалению и репликации блоков, а также периодическую отправку сообщения о состоянии 6heartbeats) и обработку запросов на чтение и запись, поступающих от клиентов файловой системы HDFS.
DataNode6узел данных) — хранит актуальные блоки данных HDFS. Фоновый процесс узла данных управляет хранилищами, подключёнными к узлу. Узлов данных может быть несколько.
Что будет, если записать много маленьких файлов в HDFS?
Кол-во мета-даты у нас вырастет, закончится CPU & RAM
Если будет много небольших файлов, тогда NameNode может быть перегружен, так как он хранит пространство имен для HDFS
Что будет, если несколько DataNode внезапно отключатся?
HDFS это увидит и самостоятельно запустится механизм востановления реплик на другие DataNode
Как проапдейдить несколько записей в большом файле на hdfs?
head -n 100000 vehicles.csv > vehicles2.csv
Опция 1: Добавить к существующему файлу echo "" | hdfs dfs -appendToFile -/user/hduser/myfile.txt echo "" | hdfs dfs -appendToFile -/user/hduser/myfile.txt ИЛИ hdfs dfs -appendToFile -/user/hduser/myfile.txt а затем введите текст на терминале. Когда вы закончите печатать, нажмите "Ctrl + D",
Option2: Получите исходный файл из HDFS в локальную файловую систему, измените его и верните на HDFS. hdfs dfs -get/user/hduser/myfile.txt vi myfile.txt #или использовать любой другой инструмент и изменить егоили использовать любой другой инструмент и изменить его hdfs dfs -put -f myfile.txt/user/hduser/myfile.txt
*Почему задачи на YARN нестабильны?
Теряем ресурс менеджер, контейнеры. Распределение ресурсов в кластере.
Что такое Hive?
Apache Hive - программное обеспечение, используемое хранилищами данных. Облегчает использование запросов и управление большими объемами данных, находящихся в распределенных хранилищах. Hive предоставляет механизм проектирования структур для этих данных и позволяет создавать запросы с использованием SQL -подобного языка, называемым HiveQL. В то же время этот язык позволяет программистам использовать их собственные запросы, когда неудобно или неэффективно использовать логику в HiveQL.
Что хранит HiveMetastore?
Хранит метаданные для таблиц Hive — схему на чтение 6schema-on-read) , расположение, информацию о столбцах в таблице, типы данных, ACL и тд.
Чем отличается external table и managed table?
Managed tables A managed table is stored under the hive.metastore.warehouse.dir path property, by default in a folder path similar to /user/hive/warehouse/databasename.db/tablename/. The default location can be overridden by the location property during table creation. If a managed table or partition is dropped, the data and metadata associated with that table or partition are deleted. If the PURGE option is not specified, the data is moved to a trash folder for a defined duration. Use managed tables when Hive should manage the lifecycle of the table, or when generating temporary tables.- External tables An external table describes the metadata / schema on external files. External table files can be accessed and managed by processes outside of Hive. External tables can access data stored in sources such as Azure Storage Volumes 6ASV) or remote HDFS locations. If the structure or partitioning of an external table is changed, an MSCK REPAIR TABLE table_name statement can be used to refresh metadata information. Use external tables when files are already present or in remote locations, and the files should remain even if the table is dropped.
*Какие форматы умеет читать Hive?
Текстовые файл, Файл последовательности6SequenceFile), Файл столбцов строк6RCFile), ORC файл
Текстовые csv-файлы, бинарные sequence-файлы, более сложные колоночные parquet-файлы и другие форматы.
*Чем отличается управление ресурсов в Hive и Impala?
Impala реализованна Клаудерой, запускается каждом узле кластера/каждай дата-ноде, принимает запросы из различных интерфейсов. не использует мап-редьюс, ни чего. Идет на прямую в hdfs с помощью своих клиентов
Чем отличается колочный формат хранения данных от строчного?
колоночные базы данных могут быть сжаты сильнее, чем строчные, что позволяет более эффективно использовать дисковое пространство. колочный метод хранения информации позволяет пропускать ненужные столбцы при чтении данных, что существенно ускоряет чтение данных и отлично подходит в случае, когда необходим небольшой объем строк или выполняются избирательные запросы, как, например, в СУБД Apache Hive. Но такой формат чтения и записи занимает больше места в оперативной памяти, поскольку, чтобы получить столбец из нескольких строк, кэшируется каждая строка.
Чем отличается parquet/orc от csv?
Apache Parquet и ORC 6Optimized Row Columnar) - это колоночно-ориентированные 6столбцовые) форматы хранения. CSV — это текстовый формат, предназначенный для представления табличных данных. Строка таблицы соответствует строке текста, которая содержит одно или несколько полей, разделенных запятыми.
Чем отличается Avro от json?
Apache Avro - это система сериализации данных, разработанная в рамках проекта Hadoop. Система использует JSON для определения структуры данных 6схемы), которые сериализуются в компактный бинарный формат.
JSON 6англ. JavaScript Object Notation) - это текстовый формат обмена данными, основанный на JavaScript. Как и многие другие текстовые форматы, JSON легко читается людьми. Несмотря на происхождение от JavaScript 6точнее, от подмножества языка стандарта ECMA-262 1999 года), формат считается независимым от языка и может использоватьсяпрактически с любым языком программирования. Для многих языков существует готовый код для создания и обработки данных в формате JSON.
*Чем отличается документориетированный формат данных от реляционного?
В объектно-ориентированных базах данных, в отличие от реляционных, хранятся не записи, а объекты. ОО-подход представляет более совершенные средства для отображения реального мира, чем реляционная модель, естественное представление данных.
Чем отличается etl и elt?
ETL — это сокращение от Extract, Transform и Load. В этом процессе инструмент ETL извлекает данные из разных исходных систем РСУБД, затем преобразует данные, например, применяет вычисления, конкатенации и т. Д., А затем загружает данные в систему хранилища данных. В ETL данные поступают из источника в цель. В ETL механизм преобразования процессов заботится о любых изменениях данных. Что такое ELT? ELT — это другой метод рассмотрения инструментального подхода к перемещению данных. Вместо преобразования данных перед их записью ELT позволяет целевой системе выполнить преобразование
ELT 6Извлечь загрузить преобразовать) – это разновидность ETL 6Извлечь преобразовать загрузить). С ELT, преобразования данных происходят сразу после их загрузки в озеро данных или хранилище. ... представляет собой процесс ELT или ETL для извлечения, агрегирования, организации, преобразования, маршрутизации, сопоставления и хранения данных независимо от их объема. предлагает структуры и методы для работы с разнообразными и сложными экосистемами данных, обеспечивая легкий доступ к ним. обеспечивает согласованность и автоматизацию разработки, тестирования и эксплуатации Инструмент ELT 6Extract, Load, and Transform) позволяет сразу загрузить извлеченные данные в аналитическое приложение без предварительной обработки, где затем происходит их преобразование. Это ускоряет получение результата и не требует от пользователя ни специализированных знаний в области программирования, ни трудоемкой и дорогой предобработки данных
Какие основные челенджы etl?
ETL 6от англ. Extract, Transform, Load — дословно «извлечение, преобразование, загрузка») это один из основных процессов в управлении хранилищами данных, который включает в себя: извлечение данных из внешних источников; их трансформация и очистка, чтобы они соответствовали потребностям бизнес-модели; и загрузка их в хранилище данных
*Какие инструменты etl вы знаете?
AWS
Для чего нужны key-value СУБД?
База данных «клю́ч-значе́ние») 6англ. key-value database или англ. key–value store) —парадигма хранения данных, предназначенная для хранения, извлечения и управления ассоциативными массивами, структура данных, более известная сегодня как словарь или хеш-таблица. Словари содержат коллекцию объектов или записей, которые, в свою очередь, содержат множество различных полей, каждое из которых содержит данные. Эти записи хранятся и извлекаются с использованием ключа, который однозначно идентифицирует запись и используется для быстрого поиска данных в базе данных.Базы данных «ключ-значение») работают совершенно иначе, чем более известные реляционные базы данных 6РБД). В РБД предварительно определяют структуру данных в базе данных как последовательность таблиц, содержащих поля с четко определенными типами данных. Экспонирование типов данных в базе данных позволяет применить ряд оптимизаций. Напротив, системы «ключ-значение») обрабатывают данные как одну непрозрачную коллекцию, которая может иметь разные поля для каждой записи. Это обеспечивает значительную гибкость и более точно следует современным концепциям, таким как объектно-ориентированное программирование. Поскольку необязательные значения не представлены заполнителями или входными параметрами, как в большинстве РБД, базы данных «ключ-значение») часто используют гораздо меньше памяти для хранения одной и той же базы данных, что может привести к значительному увеличению производительности при определенных рабочих нагрузках. Базы данных «ключ-значение») могут использовать модель согласованности, начиная от возможной согласованности до сериализации. Некоторые поддерживают упорядочение ключей. Некоторые хранят данные в оперативной памяти 6ОЗУ), в то время как другие используют твердотельные накопители или жёсткие диски.
*Какие сложности стриминга в hdfs?
HDFS может быть развернута поверх не совсем эффективных или не правильно настроенных файловых систем, что может привести к фрагментации файлов данных и потери производительности. Конечно, HDFS можно использовать для скидывая в нее все нужное и ненужное. Такой подход последнее время называется "Data Lake", но не стоит забывать, что анализировать неподготовленные данные будет сложнее в будущем. Последователи такого подхода аргументируют преимущества тем, что данные, возможно, и не придется анализировать, следовательно, нет необходимости тратить времени на их подготовку.
*Какие минусы key-value хранилищ?
Низкая производительность, отсутствие стандарта и другие недостатки ограничивали использование систем «ключ-значение») в течение многих лет, но быстрое развитие облачных вычислений после 2010 года привело к их возрождению в рамках более широкого движения NoSQL. Некоторые графовые базы данных также являются базами данных ключей, добавляя концепцию отношений 6указателей) между записями как тип данных первого класса.
Из чего состоит хранилище данных?
Хранилища данных это обобщенные и консолидированные данные в многомерном представлении. Наряду с обобщенным и консолидированным представлением данных хранилища данных также предоставляют нам инструменты онлайн-аналитической обработки 6OLAP). Эти инструменты помогают нам в интерактивном и эффективном анализе данных в многомерном пространстве. Этот анализ приводит к обобщению данных и интеллектуальному анализу данных.
Хранилища данных состоит из эталонных архитектур с необходимыми компонентами, интегрированными для совместной работы в соответствии с лучшими отраслевыми практическими рекомендациями. Современное хранилище данных включает следующее. Конвергентная база данных, которая упрощает управление всеми типами данных и предоставляет различные способы использования данных.
Какие виды хранилищ данных вы знаете?
Хранилище данных – это система, в которой собраны данные из различных источников внутри компании и эти данные используются для поддержки принятия управленческих решений. Компании все чаще переходят на облачные хранилища данных вместо традиционных локальных систем. Облачные хранилища данных имеют ряд отличий от традиционных хранилищ: Нет необходимости покупать физическое оборудование.
*Основные задачи Data governance?
Увеличить отношение количества нужных данных к ненужным, повысить качество корпоративных данных и обеспечить эффективность их повторного использования. Кроме того, дисциплина включает в себя защиту «чувствительных») конфиденциальных данных, обеспечение доверия к ним, а также управление доступом к данным и их жизненным циклом.
